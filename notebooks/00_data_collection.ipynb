{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ofc2n9y6svM7"
      },
      "source": [
        "<h1> DAT204M - HW1 Data Collection </h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GooW4OBbgEl3"
      },
      "source": [
        "## Data Collection + ETL Overview (WDI)\n",
        "\n",
        "Our journey begins with a clear objective: to gather key World Bank Development Indicators (WDI) for ASEAN countries spanning 1990 to the present. We aim to create datasets that are ready for analysis, modeling, and visualization.\n",
        "To do this, we employ an ETL (Extract, Transform, Load) pipeline:\n",
        "\n",
        "   *Extract:* Collect raw WDI data via the World Bank API.\n",
        "\n",
        "   *Transform:* Clean the data, handle missing values, and reshape it into a usable format.\n",
        "\n",
        "   *Load:* Save the final datasets for further analysis.\n",
        "\n",
        "The ETL process ensures reproducibility, consistency, and quality of our data, which is crucial when working with multi-country, multi-year indicators.\n",
        "\n",
        "\n",
        "**Outputs:**\n",
        "After we perform a basic Extract-Transform-Load (ETL) workflow, we produce a dataset containing:\n",
        "   - One row per (country, year) pair, with indicators as columns\n",
        "   - Suitable for statistical modeling or correlation analysis\n",
        "\n",
        "**Requirements:**\n",
        "    - Python 3.8+\n",
        "    - pandas, requests, urllib3, dash, plotly\n",
        "\n",
        "**Author:** Julian Roger Go, Charisse Nethercott, Gabriel Masangkay, John Carlo Gonzales, Edmar Dizon\n",
        "\n",
        "**Date:** October 23, 2025"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYAKquECkS9B"
      },
      "source": [
        "### Config: ASEAN WDI pull (countries, years, indicators)\n",
        "\n",
        "Before extracting data, we define what we want and from where:\n",
        "\n",
        "**Countries:** The 10 ASEAN nations, identified by ISO3 codes.\n",
        "\n",
        "**Timeframe:** From 1990 to the most recent available year.\n",
        "\n",
        "**Indicators:** Key metrics like energy use per capita and urban population percentage.\n",
        "\n",
        "This configuration acts as a blueprint for the ETL process, making it easy to extend in the future (e.g., adding more countries or indicators)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "69uI5jMmhQlj"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "from requests.adapters import HTTPAdapter\n",
        "from urllib3.util.retry import Retry\n",
        "\n",
        "# ASEAN-10 ISO3 country codes\n",
        "# (Source: ISO 3166-1 alpha-3 codes)\n",
        "COUNTRIES = [\n",
        "    \"BRN\",  # Brunei Darussalam\n",
        "    \"KHM\",  # Cambodia\n",
        "    \"IDN\",  # Indonesia\n",
        "    \"LAO\",  # Lao PDR\n",
        "    \"MYS\",  # Malaysia\n",
        "    \"MMR\",  # Myanmar\n",
        "    \"PHL\",  # Philippines\n",
        "    \"SGP\",  # Singapore\n",
        "    \"THA\",  # Thailand\n",
        "    \"VNM\",  # Vietnam\n",
        "]\n",
        "\n",
        "START_YEAR = 1990  # Minimum year to include in the dataset\n",
        "STEM = \"asean_energy_urban_wdi\"  # Output filename prefix\n",
        "\n",
        "# Indicator codes from the World Bank Open Data API.\n",
        "# Last two CO₂ indicators are modern EDGAR-based replacements for retired series.\n",
        "INDICATORS = {\n",
        "    \"EG.ELC.RNEW.ZS\": \"renewable_electricity_pct\",              # Renewable electricity (% of total)\n",
        "    \"EG.FEC.RNEW.ZS\": \"renewable_energy_consumption_pct\",       # Renewable energy use (% of final energy)\n",
        "    \"EG.USE.PCAP.KG.OE\": \"energy_use_kg_oe_per_capita\",         # Energy use (kg of oil equivalent per capita)\n",
        "    \"SP.POP.TOTL\": \"population_total\",                          # Total population\n",
        "    \"NY.GDP.MKTP.CD\": \"gdp_current_usd\",                        # GDP (current US$)\n",
        "    \"EN.GHG.CO2.PC.CE.AR5\": \"co2_per_capita_tco2e_excl_lulucf\", # CO₂ per capita (tCO₂e, excl. LULUCF)\n",
        "    \"EN.GHG.CO2.MT.CE.AR5\": \"co2_total_mtco2e_excl_lulucf\",     # Total CO₂ (MtCO₂e, excl. LULUCF)\n",
        "    \"SP.URB.TOTL.IN.ZS\": \"urban_pop_pct\",                       # Urban population (% of total)\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLhCJVlckVtG"
      },
      "source": [
        "**What it sets up**\n",
        "\n",
        "- `COUNTRIES`: ISO3 list for ASEAN-10. Used to loop API calls by country.\n",
        "- `START_YEAR`: drop observations earlier than this. Keeps the final dataset focused and consistent across indicators.\n",
        "- `STEM`: base filename prefix for saved outputs, for example `asean_energy_urban_wdi.parquet` or `asean_energy_urban_wdi.csv`.\n",
        "- `INDICATORS`: mapping from World Bank indicator codes to readable column names for your final DataFrame.\n",
        "\n",
        "**Notes on indicators**\n",
        "\n",
        "- Economics, energy, and urbanization focus:\n",
        "  - Renewable electricity share of total generation\n",
        "  - Renewable share of final energy use\n",
        "  - Energy use per capita (kg oil equivalent)\n",
        "  - Gross Domestic Product (in current US$)  \n",
        "  - Urban population percent\n",
        "  - Total population\n",
        "  - CO₂ per capita\n",
        "  - Total CO₂\n",
        "- Scale and units differ by series.\n",
        "- CO2 series use the EDGAR-based AR5 codes that exclude LULUCF. These are more current replacements for retired legacy codes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZQiMFXvjJi7"
      },
      "source": [
        "### Robust HTTP session for the World Bank API\n",
        "\n",
        "Interacting with APIs can be unpredictable. Network errors or transient server issues may occur. To address this, we create a `requests.Session`:\n",
        "\n",
        "*   Handles retries and timeouts gracefully.\n",
        "*   Avoids dropping requests due to temporary failures.\n",
        "\n",
        "This ensures our data collection is reliable and repeatable, which is especially important for long historical time series."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YOaLzvhKicHE"
      },
      "outputs": [],
      "source": [
        "WB_TIMEOUT = 60        # seconds per request (default 30)\n",
        "WB_PER_PAGE = 1000       # number of records per API page (smaller = fewer timeouts)\n",
        "WB_MAX_RETRIES = 5       # total retry attempts\n",
        "WB_BACKOFF = 1.5         # exponential backoff factor between retries\n",
        "\n",
        "# Robust session with retry/backoff for transient network/API issues\n",
        "_session = requests.Session()\n",
        "_retry = Retry(\n",
        "    total=WB_MAX_RETRIES,\n",
        "    connect=WB_MAX_RETRIES,\n",
        "    read=WB_MAX_RETRIES,\n",
        "    backoff_factor=WB_BACKOFF,\n",
        "    status_forcelist=[429, 500, 502, 503, 504],  # common transient server errors\n",
        "    allowed_methods=[\"GET\"],                      # only retry GET requests\n",
        "    raise_on_status=False,\n",
        ")\n",
        "_adapter = HTTPAdapter(max_retries=_retry)\n",
        "_session.mount(\"https://\", _adapter)\n",
        "_session.mount(\"http://\", _adapter)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWey_iNljMYN"
      },
      "source": [
        "**Parameters**\n",
        "\n",
        "- `WB_TIMEOUT`: per request timeout that is passed to `_session.get(..., timeout=WB_TIMEOUT)`. Prevents hangs on slow connections.\n",
        "- `WB_PER_PAGE`: page size sent to the API (example: `per_page=1000`).\n",
        "- `WB_MAX_RETRIES`: maximum number of retry attempts for eligible failures on connect and read.\n",
        "- `WB_BACKOFF`: exponential backoff factor between retries. Sleep grows with each retry, which reduces the chance of hitting rate limits.\n",
        "\n",
        "**Retry configuration**\n",
        "\n",
        "- `Retry(..., status_forcelist=[429, 500, 502, 503, 504])`: only these HTTP statuses trigger retries.\n",
        "- `allowed_methods=[\"GET\"]`: retries are applied only to idempotent GET requests.\n",
        "- `raise_on_status=False`: do not raise on HTTP status by default.\n",
        "\n",
        "The effective backoff follows an exponential pattern scaled by `WB_BACKOFF`. Each retry waits longer than the previous one.\n",
        "\n",
        "**Adapter mounting**\n",
        "\n",
        "- `_session.mount(\"https://\", _adapter)` and `.mount(\"http://\", _adapter)` attach the retrying adapter to all HTTP and HTTPS requests made with `_session`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZx-063wgui0"
      },
      "source": [
        "### World Bank API Fetch Utilities\n",
        "\n",
        "This snippet provides two helpers for pulling indicator data from the World Bank API with pagination, basic retry behavior, and safer JSON parsing.\n",
        "\n",
        "`wb_get_all_pages(url, base_params)`\n",
        "Fetches and flattens all pages from a World Bank API endpoint.\n",
        "\n",
        "`fetch_indicator_series(country, indicator, start_year)`\n",
        "Builds a clean list of yearly records for one indicator in one country."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Lwl505RUgN3w"
      },
      "outputs": [],
      "source": [
        "def wb_get_all_pages(url, base_params):\n",
        "    \"\"\"\n",
        "    Fetch all pages from the WB API with retry/backoff and safer parsing.\n",
        "    Returns list of rows or {\"error\": \"...\"} on unrecoverable issues.\n",
        "    \"\"\"\n",
        "    rows_all, page = [], 1\n",
        "\n",
        "    while True:\n",
        "        params = dict(base_params, page=page)\n",
        "        try:\n",
        "            # Use robust session + longer timeout\n",
        "            r = _session.get(url, params=params, timeout=WB_TIMEOUT)\n",
        "            r.raise_for_status()\n",
        "            data = r.json()\n",
        "        except requests.exceptions.ReadTimeout as e:\n",
        "            return {\"error\": f\"Read timeout after {WB_TIMEOUT}s: {e}\"}\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            return {\"error\": f\"HTTP error: {e}\"}\n",
        "        except ValueError as e:  # JSON decode error\n",
        "            return {\"error\": f\"Invalid JSON: {e}\"}\n",
        "\n",
        "        # API-level error payloads (e.g., retired indicator)\n",
        "        if isinstance(data, dict) and \"message\" in data:\n",
        "            messages = \"; \".join(m.get(\"value\", str(m)) for m in data.get(\"message\", []))\n",
        "            return {\"error\": messages}\n",
        "\n",
        "        # Expected shape: [pager, [rows...]]\n",
        "        if not (isinstance(data, list) and len(data) >= 2 and isinstance(data[1], list)):\n",
        "            return {\"error\": f\"Unexpected JSON: {str(data)[:200]}\"}\n",
        "\n",
        "        pager, rows = data[0], data[1]\n",
        "        rows_all.extend(rows)\n",
        "\n",
        "        total_pages = pager.get(\"pages\") or 1\n",
        "        if page >= total_pages:\n",
        "            break\n",
        "        page += 1\n",
        "\n",
        "        # Be polite; tiny delay helps avoid rate limits / throttling\n",
        "        time.sleep(0.2)\n",
        "\n",
        "    return rows_all"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIzaXjozhsXu"
      },
      "source": [
        "**Parameters**\n",
        "\n",
        "- `url` (`str`): Base API endpoint. Example: `https://api.worldbank.org/v2/country/PHL/indicator/SP.POP.TOTL`\n",
        "- `base_params` (`dict`): Query parameters shared by all pages.\n",
        "   Typical values: `{\"format\": \"json\", \"per_page\": WB_PER_PAGE}`.\n",
        "   The function adds `page=<n>` during pagination.\n",
        "\n",
        "**Behavior**\n",
        "\n",
        "1. Iterates over pages by incrementing `page=1, 2, 3, ...`.\n",
        "2. Uses the shared `_session` with a request timeout `WB_TIMEOUT`.\n",
        "3. Parses JSON and validates the expected World Bank response shape: `[pager, rows]`.\n",
        "4. Accumulates all `rows` into a single list.\n",
        "5. Sleeps briefly between pages to reduce throttling risk.\n",
        "\n",
        "**Returns**\n",
        "\n",
        "- `list`: A concatenated list of row objects from all pages on success.\n",
        "- `dict`: `{\"error\": \"<message>\"}` when an unrecoverable problem occurs, such as:\n",
        "  - Read timeout after all retries\n",
        "  - HTTP errors that cannot be retried\n",
        "  - Invalid JSON or an unexpected payload shape\n",
        "  - API-level message payloads that indicate a problem\n",
        "\n",
        "**Error signaling and examples**\n",
        "\n",
        "- Read timeout: `{\"error\": \"Read timeout after 20s: ...\"}`\n",
        "- HTTP error: `{\"error\": \"HTTP error: 502 Server Error ...\"}`\n",
        "- Invalid JSON: `{\"error\": \"Invalid JSON: ...\"}`\n",
        "- API message payload: `{\"error\": \"<joined WB 'message' values>\"}`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CU8OuTYqhXJz"
      },
      "outputs": [],
      "source": [
        "def fetch_indicator_series(country, indicator, start_year):\n",
        "    \"\"\"\n",
        "    Fetch a single indicator for a single country from the World Bank API.\n",
        "\n",
        "    Args:\n",
        "        country (str): ISO3 country code (e.g., 'PHL')\n",
        "        indicator (str): Indicator code (e.g., 'SP.POP.TOTL')\n",
        "        start_year (int): Filter out years earlier than this\n",
        "\n",
        "    Returns:\n",
        "        list of dictionaries with keys:\n",
        "            ['country', 'year', 'indicator', 'indicator_name', 'value']\n",
        "    \"\"\"\n",
        "    base = f\"https://api.worldbank.org/v2/country/{country}/indicator/{indicator}\"\n",
        "    rows_or_err = wb_get_all_pages(base, {\"format\": \"json\", \"per_page\": WB_PER_PAGE})\n",
        "\n",
        "    if isinstance(rows_or_err, dict) and \"error\" in rows_or_err:\n",
        "        print(f\"[skip] {country} | {indicator}: {rows_or_err['error']}\")\n",
        "        return []\n",
        "\n",
        "    out = []\n",
        "    for item in rows_or_err:\n",
        "        # Parse year; skip invalid entries\n",
        "        try:\n",
        "            year = int(item.get(\"date\"))\n",
        "        except (TypeError, ValueError):\n",
        "            continue\n",
        "\n",
        "        # Filter early years\n",
        "        if year < start_year:\n",
        "            continue\n",
        "\n",
        "        # Build a clean record\n",
        "        out.append({\n",
        "            \"country\": country,\n",
        "            \"year\": year,\n",
        "            \"indicator\": item.get(\"indicator\", {}).get(\"id\", indicator),\n",
        "            \"indicator_name\": item.get(\"indicator\", {}).get(\"value\", indicator),\n",
        "            \"value\": item.get(\"value\"),\n",
        "        })\n",
        "\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4r4sWfZ9hpHA"
      },
      "source": [
        "**Parameters**\n",
        "\n",
        "- `country` (`str`): ISO3 country code. Example: `\"PHL\"`, `\"IDN\"`.\n",
        "- `indicator` (`str`): Indicator code. Example: `\"SP.POP.TOTL\"`, `\"NY.GDP.MKTP.CD\"`.\n",
        "- `start_year` (`int`): Minimum year to keep. Rows with `year < start_year` are dropped.\n",
        "\n",
        "**Behavior**\n",
        "\n",
        "1. Builds the endpoint\n",
        "    `https://api.worldbank.org/v2/country/{country}/indicator/{indicator}`\n",
        "2. Calls `wb_get_all_pages` with `{\"format\": \"json\", \"per_page\": WB_PER_PAGE}`.\n",
        "3. If `wb_get_all_pages` returns an error dict, prints a `[skip]` message and returns an empty list.\n",
        "4. Iterates over rows, parses `date` to an integer `year`, and drops rows with invalid or too-early years.\n",
        "5. Constructs clean records with a stable shape.\n",
        "\n",
        "**Returns**\n",
        "\n",
        "A `list[dict]`, each record with keys:\n",
        "\n",
        "- `country` (`str`): Same as input country code\n",
        "- `year` (`int`): Parsed year\n",
        "- `indicator` (`str`): Indicator code. Falls back to the requested code if missing in the payload\n",
        "- `indicator_name` (`str`): Indicator descriptive name. Falls back to the requested code if missing\n",
        "- `value` (`float | int | None`): Reported value for that year. May be `None` if the World Bank has no value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJ3M8qORoDPk"
      },
      "source": [
        "### Time-Series Imputation and Missing Data Analysis\n",
        "\n",
        "To improve data completeness and reliability, two helper functions handle remaining gaps after cleaning:\n",
        "\n",
        "- `impute_time_series_data(df)` fills missing `value`s within each country–indicator series using forward fill and linear interpolation, creating smoother and more continuous time trends.\n",
        "- `analyze_missing_data(wide_df)` audits the final dataset, counting missing indicators per country-year and summarizing remaining NaNs by column.\n",
        "\n",
        "Together, they ensure the dataset is consistent, well-imputed, and ready for analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KFxXsA_2mlhG"
      },
      "outputs": [],
      "source": [
        "def impute_time_series_data(df):\n",
        "    \"\"\"Performs time-series imputation on the 'value' column.\"\"\"\n",
        "    print(\"Applying time-series imputation (Forward Fill + Linear Interpolation)...\")\n",
        "\n",
        "    df = df.sort_values([\"country\", \"indicator\", \"year\"]).reset_index(drop=True)\n",
        "\n",
        "    df[\"value\"] = (\n",
        "        df.groupby([\"country\", \"indicator\"])[\"value\"]\n",
        "        .transform(lambda x: x.interpolate(method=\"linear\").ffill().bfill())\n",
        "    )\n",
        "\n",
        "    initial_na_count = df[\"value\"].isna().sum()\n",
        "    if initial_na_count > 0:\n",
        "        print(f\"Warning: {initial_na_count} NaN values remain (likely due to missing data at the start of a series).\")\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoauphkjmhpm"
      },
      "source": [
        "**Parameters**\n",
        "\n",
        "- `df` (`pd.DataFrame`): Long-format data with at least `country`, `indicator`, `year`, and `value`.\n",
        "\n",
        "**Returns**\n",
        "\n",
        "- `pd.DataFrame`: Same columns as input, with `value` imputed where possible.\n",
        "\n",
        "**Behavior & assumptions**\n",
        "\n",
        "- Sorts by `country`, `indicator`, `year` to ensure chronological interpolation.\n",
        "- For each `country`–`indicator` series:\n",
        "  - `ffill()` fills gaps using prior known values (good for short runs of missing data).\n",
        "  - `interpolate(method=\"linear\")` fills remaining internal gaps between known points.\n",
        "- Leading NaNs (at the start of a series) cannot be forward-filled/interpolated and are reported.\n",
        "\n",
        "**When to use**\n",
        "\n",
        "- After coercing `value` to numeric and before pivoting to wide format.\n",
        "- As part of the “Handling Missing Data” requirement in the cleaning workflow.\n",
        "\n",
        "**Notes**\n",
        "\n",
        "- Interpolation assumes roughly linear change between adjacent years."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "X-rHtqyPnS3P"
      },
      "outputs": [],
      "source": [
        "def analyze_missing_data(wide_df):\n",
        "    \"\"\"\n",
        "    Performs the analysis of remaining missing values and prints a report.\n",
        "    This function is now called within main() to ensure wide_df is defined.\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"ANALYSIS: Missing Indicator Count Report\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Count NaNs per row\n",
        "    wide_df['missing_indicator_count'] = wide_df.isna().sum(axis=1)\n",
        "\n",
        "    # Filter for only the rows that actually have missing data\n",
        "    rows_with_nans = wide_df[wide_df['missing_indicator_count'] > 0].copy()\n",
        "\n",
        "    if rows_with_nans.empty:\n",
        "        print(\"No missing indicator values remain in the wide dataset after imputation.\")\n",
        "    else:\n",
        "        # Sort to see which country-years have the highest count of NaNs\n",
        "        report_df = rows_with_nans.sort_values(\n",
        "            by='missing_indicator_count', ascending=False\n",
        "        ).head(10)\n",
        "\n",
        "        print(f\"Total rows (country-years) with one or more NaNs: {len(rows_with_nans):,}\")\n",
        "        print(\"\\nTop 10 rows with the highest number of missing indicators:\")\n",
        "\n",
        "        # Show only the identifying columns and the new NaN count\n",
        "        print(report_df[['country', 'year', 'missing_indicator_count']].to_string(index=False))\n",
        "\n",
        "    print(\"\\n--- Summary of Remaining Gaps ---\")\n",
        "    # Show the total count of NaNs remaining in each column (indicator)\n",
        "    print(\"Total remaining NaNs per indicator column:\")\n",
        "    # We drop 'missing_indicator_count' since we just added it and it will be zero\n",
        "    print(wide_df.drop(columns=['missing_indicator_count'], errors='ignore').isna().sum().rename('Total NaNs').to_string())\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    return wide_df # Return the modified DataFrame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IE8_RDAYmh2Q"
      },
      "source": [
        "**Parameters**\n",
        "\n",
        "- `wide_df` (`pd.DataFrame`): Wide-format table with columns `country`, `year`, and one column per indicator.\n",
        "\n",
        "**Returns**\n",
        "\n",
        "- `pd.DataFrame`: The same frame with an added helper column `missing_indicator_count` (you can drop it later).\n",
        "\n",
        "**What it reports**\n",
        "\n",
        "- Number of missing indicator values per row (`country`–`year`).\n",
        "- Top 10 `country`–`year` combinations with the most missing indicators.\n",
        "- Total NaNs per indicator column (useful to decide where to focus imputation or filtering).\n",
        "\n",
        "**When to use**\n",
        "\n",
        "- After you’ve created the wide dataset (post-pivot) and optionally run imputation.\n",
        "- As evidence for your **Handling Missing Data** discussion: it quantifies what remains."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDz1EYDdkobJ"
      },
      "source": [
        "### End-to-end ETL + Imputation + Missingness Audit (ASEAN WDI)\n",
        "\n",
        "This block runs the full pipeline: extract World Bank indicators for ASEAN, clean and type-coerce, impute gaps in long format, pivot to wide, analyze remaining missingness, apply a final reliability filter, and save outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwhtnSKxgT30",
        "outputId": "067b4c63-ebd0-44b7-d47b-e456a89ae680"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fetching World Bank data for ASEAN countries...\n",
            "\n",
            "[skip] SGP | SP.URB.TOTL.IN.ZS: HTTP error: 429 Client Error: Too Many Requests for url: https://api.worldbank.org/v2/country/SGP/indicator/SP.URB.TOTL.IN.ZS?format=json&per_page=1000&page=1\n",
            "Applying time-series imputation (Forward Fill + Linear Interpolation)...\n",
            "\n",
            "Rows (wide): 350  | Year range: 1990-2024  | Countries: 10\n",
            "\n",
            "==================================================\n",
            "ANALYSIS: Missing Indicator Count Report\n",
            "==================================================\n",
            "Total rows (country-years) with one or more NaNs: 35\n",
            "\n",
            "Top 10 rows with the highest number of missing indicators:\n",
            "country  year  missing_indicator_count\n",
            "    SGP  1990                        1\n",
            "    SGP  2016                        1\n",
            "    SGP  2010                        1\n",
            "    SGP  2011                        1\n",
            "    SGP  2012                        1\n",
            "    SGP  2013                        1\n",
            "    SGP  2014                        1\n",
            "    SGP  2015                        1\n",
            "    SGP  2017                        1\n",
            "    SGP  2008                        1\n",
            "\n",
            "--- Summary of Remaining Gaps ---\n",
            "Total remaining NaNs per indicator column:\n",
            "short_name\n",
            "country                              0\n",
            "year                                 0\n",
            "co2_per_capita_tco2e_excl_lulucf     0\n",
            "co2_total_mtco2e_excl_lulucf         0\n",
            "energy_use_kg_oe_per_capita          0\n",
            "gdp_current_usd                      0\n",
            "population_total                     0\n",
            "renewable_electricity_pct            0\n",
            "renewable_energy_consumption_pct     0\n",
            "urban_pop_pct                       35\n",
            "==================================================\n",
            "\n",
            "Top 10 rows (wide) after cleanup and analysis:\n",
            "country  year  co2_per_capita_tco2e_excl_lulucf  co2_total_mtco2e_excl_lulucf  energy_use_kg_oe_per_capita  gdp_current_usd  population_total  renewable_electricity_pct  renewable_energy_consumption_pct  urban_pop_pct  missing_indicator_count\n",
            "    BRN  1990                         16.843458                        4.3000                  6766.202658     6.039881e+09          255292.0                        0.0                               0.7         66.438                        0\n",
            "    BRN  1991                         18.696020                        4.9095                  7438.262038     6.284497e+09          262596.0                        0.0                               0.4         66.585                        0\n",
            "    BRN  1992                         19.868514                        5.3613                  7783.232736     6.327966e+09          269839.0                        0.0                               0.2         67.078                        0\n",
            "    BRN  1993                         19.535619                        5.4108                  7299.532663     6.203340e+09          276971.0                        0.0                               0.0         67.604                        0\n",
            "    BRN  1994                         19.338170                        5.4938                  6603.066579     6.467783e+09          284091.0                        0.0                               0.0         68.126                        0\n",
            "    BRN  1995                         19.964629                        5.8136                  7718.414711     7.700144e+09          291195.0                        0.0                               0.0         68.644                        0\n",
            "    BRN  1996                         20.475667                        6.1074                  7585.308657     7.663377e+09          298276.0                        0.0                               0.0         69.158                        0\n",
            "    BRN  1997                         21.290950                        6.5010                  7652.680694     7.793034e+09          305341.0                        0.0                               0.0         69.666                        0\n",
            "    BRN  1998                         18.384365                        5.7430                  7448.312776     5.550846e+09          312385.0                        0.0                               0.0         70.170                        0\n",
            "    BRN  1999                         18.810248                        6.0082                  7427.447777     6.309070e+09          319411.0                        0.0                               0.0         70.669                        0\n"
          ]
        }
      ],
      "source": [
        "def main():\n",
        "    \"\"\"\n",
        "    Executes the full Extract-Transform-Load (ETL) process.\n",
        "    \"\"\"\n",
        "    all_rows = []\n",
        "\n",
        "    # --- EXTRACT ---\n",
        "    print(\"Fetching World Bank data for ASEAN countries...\\n\")\n",
        "    for c in COUNTRIES:\n",
        "        for code in INDICATORS:\n",
        "            all_rows.extend(fetch_indicator_series(c, code, START_YEAR))\n",
        "\n",
        "    # --- TRANSFORM ---\n",
        "    long_df = pd.DataFrame(all_rows)\n",
        "    if long_df.empty:\n",
        "        raise SystemExit(\"No data retrieved. Check your internet connection or indicator list.\")\n",
        "\n",
        "    # Data cleaning and type coercion\n",
        "    long_df[\"year\"] = pd.to_numeric(long_df[\"year\"], errors=\"coerce\").astype(\"Int64\")\n",
        "    long_df[\"value\"] = pd.to_numeric(long_df[\"value\"], errors=\"coerce\")\n",
        "    long_df[\"country\"] = long_df[\"country\"].astype(str).str.strip().str.upper()\n",
        "    long_df[\"indicator\"] = long_df[\"indicator\"].astype(str).str.strip()\n",
        "    long_df[\"indicator_name\"] = long_df[\"indicator_name\"].astype(str).str.strip()\n",
        "    long_df = long_df.dropna(subset=[\"year\"]).copy()\n",
        "    long_df[\"year\"] = long_df[\"year\"].astype(int)\n",
        "    long_df = long_df.drop_duplicates(subset=[\"country\", \"year\", \"indicator\"])\n",
        "\n",
        "    # Impute missing values within time series\n",
        "    long_df = impute_time_series_data(long_df.copy())\n",
        "\n",
        "    # Map short indicator names and sort\n",
        "    long_df[\"short_name\"] = long_df[\"indicator\"].map(INDICATORS)\n",
        "    long_df = long_df.sort_values([\"country\", \"year\", \"indicator\"]).reset_index(drop=True)\n",
        "\n",
        "    # Pivot to wide format (one row per country-year)\n",
        "    wide_df = (\n",
        "        long_df\n",
        "        .pivot(index=[\"country\", \"year\"], columns=\"short_name\", values=\"value\")\n",
        "        .reset_index()\n",
        "        .sort_values([\"country\", \"year\"])\n",
        "        .reset_index(drop=True)\n",
        "    )\n",
        "\n",
        "    # --- OUTPUT & ANALYSIS ---\n",
        "    print(\n",
        "        f\"\\nRows (wide): {len(wide_df):,}  | \"\n",
        "        f\"Year range: {wide_df['year'].min()}-{wide_df['year'].max()}  | \"\n",
        "        f\"Countries: {wide_df['country'].nunique()}\"\n",
        "    )\n",
        "\n",
        "    # Analyze remaining missing values (adds 'missing_indicator_count')\n",
        "    wide_df = analyze_missing_data(wide_df)\n",
        "\n",
        "    # --- LOAD ---\n",
        "    # Save imputed long data and cleaned wide data\n",
        "    wide_df.to_csv(f\"../data/{STEM}.csv\", index=False)\n",
        "\n",
        "    # Final preview\n",
        "    print(\"\\nTop 10 rows (wide) after cleanup and analysis:\")\n",
        "    print(wide_df.head(10).to_string(index=False))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLpVq4QbkpFI"
      },
      "source": [
        "**What this pipeline does**\n",
        "\n",
        "**1) Extract**\n",
        "\n",
        "- Iterates `COUNTRIES × INDICATORS`, calling `fetch_indicator_series(...)`.\n",
        "- Collects all records into `all_rows`.\n",
        "\n",
        "**2) Transform (clean + coerce)**\n",
        "\n",
        "- Builds `long_df` and applies core cleaning:\n",
        "  - **Type conversion:** `year`/`value` → numeric; `year` to `Int64` then `int`.\n",
        "  - **String standardization:** trim/uppercase country; trim indicator fields.\n",
        "  - **Handle missing:** drop rows with missing `year` after coercion.\n",
        "  - **Deduplication:** remove duplicate keys (`country`, `year`, `indicator`).\n",
        "- **Imputation:** `impute_time_series_data(long_df)` forward-fills and linearly interpolates `value` within each `country×indicator` series.\n",
        "- **Restructuring:** map readable `short_name`, sort, then **pivot to wide**: one row per (`country`,`year`) and one column per indicator.\n",
        "\n",
        "**3) Output & analysis (audit missingness)**\n",
        "\n",
        "- Prints summary (rows, year range, country count).\n",
        "- Runs `analyze_missing_data(wide_df)` to add `missing_indicator_count` and print a missingness report.\n",
        "\n",
        "**4) Load (persist results)**\n",
        "\n",
        "- Saves:\n",
        "  - `\"{STEM}_long.csv\"` - long, **imputed** time series.\n",
        "  - `\"{STEM}_wide.csv\"` - wide, **cleaned** (post-threshold) table."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kJFA_pVfACw"
      },
      "source": [
        "### Final Result from pre-processing\n",
        "\n",
        "- Sets global pandas display options so prints won’t truncate.\n",
        "- Loads the cleaned wide file `{STEM}.csv`.\n",
        "- Prints **all rows and columns** via `.to_string()`.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
