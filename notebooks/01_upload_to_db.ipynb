{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6c1569b",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "This notebook implements **Part 1: Data Persistence and Pipeline** for the DAT204M HW2 project.\n",
    "\n",
    "It demonstrates how to securely upload a cleaned dataset from a local CSV file into a **cloud database (Supabase)** using Python.\n",
    "\n",
    "The goal is to establish a reusable and professional data pipeline that can:\n",
    "- Read and validate the cleaned CSV data.\n",
    "- Sanitize missing or invalid values (e.g., NaN → None).\n",
    "- Create a cloud database table matching the dataset schema.\n",
    "- Upload or upsert the records to Supabase programmatically.\n",
    "- Verify successful persistence by querying one or more rows.\n",
    "\n",
    "This step forms the foundation for **Part 2: Analysis and Modeling**, where the data will be retrieved directly from the cloud."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd33f77",
   "metadata": {},
   "source": [
    "## 2. Database Setup\n",
    "\n",
    "We use **Supabase**, a managed PostgreSQL service with a Python SDK (`supabase-py`) for easy integration.\n",
    "\n",
    "- The `.env` file securely stores credentials:\n",
    "```\n",
    "SUPABASE_URL=https://<PROJECT_REF>.supabase.co\n",
    "SUPABASE_SERVICE_ROLE_KEY=<your_service_key>\n",
    "```\n",
    "- These credentials are loaded via `python-dotenv` to avoid hardcoding sensitive keys.\n",
    "- The connection uses HTTPS REST endpoints (no direct port access).\n",
    "\n",
    "Supabase is chosen for this project because it offers:\n",
    "- A generous free tier.\n",
    "- PostgreSQL compatibility.\n",
    "- RESTful API and SDK support.\n",
    "- Built-in data browser for verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75a68bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from supabase import create_client, Client\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "url: str = os.environ.get(\"SUPABASE_URL\")\n",
    "key: str = os.environ.get(\"SUPABASE_SERVICE_ROLE_KEY\")\n",
    "\n",
    "supabase: Client = create_client(url, key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727c460d",
   "metadata": {},
   "source": [
    "## 3. Load and Inspect the Cleaned Dataset\n",
    "\n",
    "We begin with the final, cleaned dataset (`asean_energy_urban_wdi_wide.csv` or `brn_energy.csv`) produced in HW1.\n",
    "\n",
    "The dataset includes energy, emissions, GDP, and population indicators for ASEAN countries.\n",
    "\n",
    "Key data-cleaning steps from HW1 ensure:\n",
    "- Consistent column names and types.\n",
    "- No duplicated rows.\n",
    "- Proper numeric formatting.\n",
    "\n",
    "Here, we will verify:\n",
    "- Data shape (rows × columns).\n",
    "- Sample records for structure validation.\n",
    "- Basic completeness before upload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7af06bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to upload: 350 rows, 11 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>co2_per_capita_tco2e_excl_lulucf</th>\n",
       "      <th>co2_total_mtco2e_excl_lulucf</th>\n",
       "      <th>energy_use_kg_oe_per_capita</th>\n",
       "      <th>gdp_current_usd</th>\n",
       "      <th>population_total</th>\n",
       "      <th>renewable_electricity_pct</th>\n",
       "      <th>renewable_energy_consumption_pct</th>\n",
       "      <th>urban_pop_pct</th>\n",
       "      <th>missing_indicator_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BRN</td>\n",
       "      <td>1990</td>\n",
       "      <td>16.843458</td>\n",
       "      <td>4.3</td>\n",
       "      <td>6766.202658</td>\n",
       "      <td>6039881086.68157</td>\n",
       "      <td>255292.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>66.438</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BRN</td>\n",
       "      <td>1991</td>\n",
       "      <td>18.69602</td>\n",
       "      <td>4.9095</td>\n",
       "      <td>7438.262038</td>\n",
       "      <td>6284497300.38401</td>\n",
       "      <td>262596.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>66.585</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BRN</td>\n",
       "      <td>1992</td>\n",
       "      <td>19.868514</td>\n",
       "      <td>5.3613</td>\n",
       "      <td>7783.232736</td>\n",
       "      <td>6327966444.87488</td>\n",
       "      <td>269839.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>67.078</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BRN</td>\n",
       "      <td>1993</td>\n",
       "      <td>19.535619</td>\n",
       "      <td>5.4108</td>\n",
       "      <td>7299.532663</td>\n",
       "      <td>6203339925.05349</td>\n",
       "      <td>276971.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.604</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BRN</td>\n",
       "      <td>1994</td>\n",
       "      <td>19.33817</td>\n",
       "      <td>5.4938</td>\n",
       "      <td>6603.066579</td>\n",
       "      <td>6467782521.31603</td>\n",
       "      <td>284091.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.126</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country  year co2_per_capita_tco2e_excl_lulucf co2_total_mtco2e_excl_lulucf  \\\n",
       "0     BRN  1990                        16.843458                          4.3   \n",
       "1     BRN  1991                         18.69602                       4.9095   \n",
       "2     BRN  1992                        19.868514                       5.3613   \n",
       "3     BRN  1993                        19.535619                       5.4108   \n",
       "4     BRN  1994                         19.33817                       5.4938   \n",
       "\n",
       "  energy_use_kg_oe_per_capita   gdp_current_usd population_total  \\\n",
       "0                 6766.202658  6039881086.68157         255292.0   \n",
       "1                 7438.262038  6284497300.38401         262596.0   \n",
       "2                 7783.232736  6327966444.87488         269839.0   \n",
       "3                 7299.532663  6203339925.05349         276971.0   \n",
       "4                 6603.066579  6467782521.31603         284091.0   \n",
       "\n",
       "  renewable_electricity_pct renewable_energy_consumption_pct urban_pop_pct  \\\n",
       "0                       0.0                              0.7        66.438   \n",
       "1                       0.0                              0.4        66.585   \n",
       "2                       0.0                              0.2        67.078   \n",
       "3                       0.0                              0.0        67.604   \n",
       "4                       0.0                              0.0        68.126   \n",
       "\n",
       "  missing_indicator_count  \n",
       "0                       0  \n",
       "1                       0  \n",
       "2                       0  \n",
       "3                       0  \n",
       "4                       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CSV_PATH  = \"../data/asean_energy_urban_wdi.csv\"\n",
    "TABLE_NAME = \"brn_indicators\"\n",
    "BATCH_SIZE = 1000  \n",
    "\n",
    "# 1) read\n",
    "df = pd.read_csv(\n",
    "    CSV_PATH,\n",
    "    keep_default_na=True,\n",
    "    na_values=[\"\", \"NA\", \"NaN\", \"nan\"]\n",
    ")\n",
    "\n",
    "# 2) sanitize to JSON-safe: NaN/±inf -> None; ensure object dtype before None\n",
    "df = df.replace([np.inf, -np.inf], np.nan).astype(object).where(pd.notnull(df), None)\n",
    "\n",
    "# 3) records + preflight check (will raise if any NaN/Infinity slipped through)\n",
    "records = df.to_dict(orient=\"records\")\n",
    "json.dumps(records, allow_nan=False)\n",
    "\n",
    "print(f\"Ready to upload: {len(records)} rows, {len(df.columns)} columns\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ccc7cc",
   "metadata": {},
   "source": [
    "Before uploading to Supabase, the data must be JSON-serializable.\n",
    "\n",
    "Supabase’s REST API does not accept `NaN`, `inf`, or `-inf` values (invalid JSON tokens).\n",
    "\n",
    "We handle this by:\n",
    "- Converting all NumPy floats (`np.nan`, `np.inf`) → Python `None`.\n",
    "- Ensuring numeric and string types are valid.\n",
    "- Validating payload with `json.dumps(..., allow_nan=False)`.\n",
    "\n",
    "This guarantees that the upload will succeed without syntax errors like  \n",
    "`Token \"NaN\" is invalid (22P02)`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205474e8",
   "metadata": {},
   "source": [
    "## 4. Data Upload and Verification\n",
    "\n",
    "We use the Supabase Python client’s `upsert()` method to insert or update rows.\n",
    "\n",
    "**Key properties of this approach:**\n",
    "- `upsert()` inserts new rows or updates existing ones based on the primary key (`country`, `year`).\n",
    "- Data is sent in small batches (≤500 rows) to stay under the 10 MB REST payload limit.\n",
    "- Each batch is validated locally before upload.\n",
    "- Verification:\n",
    "  - Query one known row via `maybe_single()`.\n",
    "  - Count total rows in the cloud table.\n",
    "\n",
    "This ensures the dataset is now persisted in a cloud-accessible format for subsequent analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fd4a35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading 350 rows in 1 batch(es) to 'brn_indicators'...\n",
      "  ✓ Batch 1/1 — 350 rows\n",
      "Upload complete\n"
     ]
    }
   ],
   "source": [
    "from math import ceil\n",
    "from postgrest import APIError  # optional: to catch specific API errors\n",
    "\n",
    "total = len(records)\n",
    "num_batches = ceil(total / BATCH_SIZE)\n",
    "print(f\"Uploading {total} rows in {num_batches} batch(es) to '{TABLE_NAME}'...\")\n",
    "\n",
    "for i in range(0, total, BATCH_SIZE):\n",
    "    batch = records[i:i + BATCH_SIZE]\n",
    "    try:\n",
    "        resp = (\n",
    "            supabase\n",
    "            .table(TABLE_NAME)\n",
    "            .upsert(batch, returning=\"minimal\")  # don't echo rows back\n",
    "            .execute()\n",
    "        )\n",
    "        # success: no exception thrown\n",
    "        print(f\"  ✓ Batch {i//BATCH_SIZE + 1}/{num_batches} — {len(batch)} rows\")\n",
    "    except APIError as e:\n",
    "        # PostgREST / Supabase API error (e.g., JSON NaN, RLS, etc.)\n",
    "        raise RuntimeError(f\"Batch starting at {i} failed: {e.message}\") from e\n",
    "    except Exception as e:\n",
    "        # Any other client/network error\n",
    "        raise RuntimeError(f\"Batch starting at {i} failed: {e}\") from e\n",
    "\n",
    "print(\"Upload complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc057833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One row: {'country': 'BRN', 'year': 1990, 'co2_per_capita_tco2e_excl_lulucf': 16.8434576876675, 'co2_total_mtco2e_excl_lulucf': 4.3, 'energy_use_kg_oe_per_capita': 6766.20265813163, 'gdp_current_usd': 6039881086.68157, 'population_total': 255292, 'renewable_electricity_pct': 0, 'renewable_energy_consumption_pct': 0.7, 'urban_pop_pct': 66.438, 'missing_indicator_count': 0}\n",
      "Total rows: 350\n"
     ]
    }
   ],
   "source": [
    "# Verify one row\n",
    "probe = records[0]\n",
    "q = supabase.table(TABLE_NAME).select(\"*\")\n",
    "for k in (\"country\", \"year\"):\n",
    "    if k in probe:\n",
    "        q = q.eq(k, probe[k])\n",
    "row = q.limit(1).maybe_single().execute()\n",
    "print(\"One row:\", row.data)\n",
    "\n",
    "# Count rows\n",
    "count_resp = supabase.table(TABLE_NAME).select(\"country\", count=\"exact\").execute()\n",
    "print(\"Total rows:\", count_resp.count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828595b8",
   "metadata": {},
   "source": [
    "## 6. Summary\n",
    "\n",
    "This notebook successfully demonstrates:\n",
    "- A secure and reusable cloud upload pipeline.\n",
    "- Proper credential handling with `.env`.\n",
    "- Robust error handling and data validation.\n",
    "- Direct integration between local analytics and cloud data storage.\n",
    "\n",
    "The resulting Supabase table (`brn_indicators`) is now ready for analysis in the next phase (`02_analysis_from_db.ipynb`)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
