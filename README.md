# DAT204M HW2 â€” Cloud Data Pipeline and Analysis (Track A)

### ğŸ“˜ Course
**DAT204M â€“ Data Collection and Processing**  
De La Salle University  
Term 1 AY 2025â€“2026  

---

## ğŸ“– Project Overview

This project demonstrates a complete data pipeline from **local CSV â†’ cloud database â†’ analysis notebook**.

It builds directly on **HW1 (data collection and cleaning)** and fulfills the HW2 objectives:

1. Persist clean data into a **cloud database** (Supabase).  
2. Query data **directly from the cloud** for exploratory data analysis (EDA) and modeling.  
3. Apply either a **simple machine learning model** or an **in-depth statistical analysis**.  
4. Document the workflow, database schema, and results in professional, reproducible notebooks.

---

## âš™ï¸ Architecture

```
ğŸ—„ï¸ 00_data_collection.ipynb
     â”‚
     â–¼
ğŸ“„ CSV (clean dataset)
     â”‚
     â–¼
ğŸ§© 01_upload_to_db.ipynb
     â”œâ”€â”€ reads local CSV
     â”œâ”€â”€ sanitizes NaN / inf â†’ None (JSON-safe)
     â”œâ”€â”€ creates table schema (if needed)
     â”œâ”€â”€ uploads to Supabase via REST API
     â–¼
â˜ï¸ Supabase Cloud Database (PostgreSQL)
     â”‚
     â–¼
ğŸ“Š 02_analysis_from_db.ipynb
     â”œâ”€â”€ queries data via Supabase client
     â”œâ”€â”€ performs EDA & visualizations
     â”œâ”€â”€ trains Linear Regression model
     â”œâ”€â”€ evaluates & interprets results
```

---

## ğŸ§° Files Included

| File | Description |
|------|--------------|
| `00_data_collection.ipynb` | Collects data from World Bank Open Data. |
| `01_upload_to_db.ipynb` | Uploads the cleaned CSV to Supabase securely. |
| `02_analysis_from_db.ipynb` | Queries from Supabase, performs EDA & ML modeling. |
| `requirements.txt` | List of Python dependencies (see below). |
| `.env` *(not committed)* | Environment variables for Supabase credentials. |
| `README.md` | This documentation file. |
| `data/` | Folder containing your cleaned CSV file. |

---

## ğŸ—ï¸ Environment Setup

### 1ï¸âƒ£ Prerequisites
- Python â‰¥ 3.9  
- Jupyter Notebook or JupyterLab  
- Supabase account (free tier)

### 2ï¸âƒ£ Clone and install
```bash
git clone <your-repo-url>
cd <your-repo-folder>
pip install -r requirements.txt
```

### 3ï¸âƒ£ Create a `.env` file
```bash
SUPABASE_URL=https://<PROJECT_REF>.supabase.co
SUPABASE_KEY=<your-anon-key>
```

---

## ğŸš€ Notebook 1: Data Persistence (`01_upload_to_db.ipynb`)

**Purpose:** move the cleaned CSV into Supabase.

### Key steps
1. Read the local cleaned CSV.  
2. Sanitize all missing values (`NaN`, `inf`) â†’ `None`.  
3. Generate a matching `CREATE TABLE` SQL (for Supabase SQL editor).  
4. Batch upload using `supabase-py`â€™s `upsert()` method.  
5. Verify with `maybe_single()` query and record count.

### Outputs
- Cloud table: `brn_indicators`  
- Safe, reproducible upload process with secure credentials.

---

## ğŸ“ˆ Notebook 2: Analysis from DB (`02_analysis_from_db.ipynb`)

**Purpose:** query data directly from Supabase for Track A (Simple ML Model).

### Key steps
1. Connect via `supabase-py` client.  
2. Query all rows from the `brn_indicators` table.  
3. Perform EDA:
   - Summary statistics  
   - Correlation heatmap & pairplots  
   - Time-series for sample country  
4. Model:
   - Train/test split  
   - Linear Regression (`scikit-learn`)  
   - Evaluate RÂ² and RMSE  
5. Visualize feature importance & prediction diagnostics.

### Example results
- **RÂ² â‰ˆ 0.70â€“0.90** depending on dataset.  
- Strong positive relationship between energy use per capita and COâ‚‚ emissions.  
- Renewable energy share shows slight negative effect.

---

## ğŸ§® Dependencies

See [`requirements.txt`](requirements.txt) for full list.  
Main packages:

| Category | Packages |
|-----------|-----------|
| Core data | `pandas`, `numpy` |
| Visualization | `matplotlib`, `seaborn` |
| ML Modeling | `scikit-learn` |
| Cloud Database | `supabase`, `postgrest`, `sqlalchemy`, `psycopg2-binary` |
| Environment Mgmt | `python-dotenv` |

Install all:
```bash
pip install -r requirements.txt
```

---

## ğŸ§© Database Schema Example

```sql
create table if not exists brn_indicators (
  country text,
  year int,
  co2_per_capita_tco2e_excl_lulucf double precision,
  co2_total_mtco2e_excl_lulucf double precision,
  energy_use_kg_oe_per_capita double precision,
  gdp_current_usd double precision,
  population_total double precision,
  renewable_electricity_pct double precision,
  renewable_energy_consumption_pct double precision,
  urban_pop_pct double precision,
  missing_indicator_count int,
  primary key (country, year)
);
```

---

## ğŸ”’ Security Notes

- Store credentials only in `.env`.  
- Never expose the **Service Role Key** publicly.  
- All uploads use HTTPS REST calls (`supabase-py`), no direct DB ports.  
- RLS (Row Level Security) can be configured later if needed.

---

## ğŸ Deliverables Summary

| Deliverable | Description | Status |
|--------------|-------------|--------|
| âœ… Notebook 1 | CSV â†’ Supabase Pipeline | Complete |
| âœ… Notebook 2 | Supabase â†’ EDA + ML | Complete |
| âœ… requirements.txt | Dependencies | Included |
| âœ… README.md | Documentation | Included |

---

## ğŸ§  Learning Reflections

- Implemented real-world data pipeline using a modern cloud DB.  
- Learned secure handling of environment variables and credentials.  
- Practiced end-to-end reproducibility (data â†’ model).  
- Applied linear regression and interpreted coefficients.  
- Reinforced principles of reusability and modular design.

---

## ğŸ“š References
- [Supabase Python Client Docs](https://supabase.com/docs/reference/python)  
- [pandas Documentation](https://pandas.pydata.org/docs/)  
- [scikit-learn Documentation](https://scikit-learn.org/stable/)  
- [Matplotlib & Seaborn Visualization](https://seaborn.pydata.org/)  

---

Â© 2025 De La Salle University â€“ Masters of Science Data Science  
Authors: Julian Roger Go, Charisse Nethercott, Gabriel Masangkay, John Carlo Gonzales, Edmar Dizon
